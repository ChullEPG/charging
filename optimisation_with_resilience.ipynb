{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# read files\n",
    "import os\n",
    "import glob \n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# math\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# optimisation \n",
    "import pulp\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# spatial data analysis\n",
    "import geopandas as gpd\n",
    "from geopy.distance import geodesic\n",
    "import utm\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "import re\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import MultiPoint \n",
    "from shapely.geometry import LineString\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#other \n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_incremental_distance(row, df):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        row (_type_): _description_\n",
    "        df (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    if row.name == 0: # for the first row, set incremental distance to 0\n",
    "        return 0\n",
    "    else:\n",
    "        # calculate the distance between the current observation and the previous observation\n",
    "        prev_lat = df.at[row.name - 1, 'Latitude']\n",
    "        prev_lon = df.at[row.name - 1, 'Longitude']\n",
    "        curr_lat = row['Latitude']\n",
    "        curr_lon = row['Longitude']\n",
    "        prev_coord = (prev_lat, prev_lon)\n",
    "        curr_coord = (curr_lat, curr_lon)\n",
    "        return geodesic(prev_coord, curr_coord).kilometers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_decimal(dms_string):\n",
    "    # Split the DMS string into its parts (degrees, minutes, seconds, direction)\n",
    "    parts = re.split('[?\\'\"]+', dms_string)\n",
    "    degrees = float(parts[0])\n",
    "    minutes = float(parts[1])\n",
    "    seconds = float(parts[2])\n",
    "    direction = parts[3]\n",
    "    \n",
    "    # Convert the DMS values to decimal\n",
    "    decimal = degrees + (minutes / 60) + (seconds / 3600)\n",
    "    if direction in ('S', 'W'):\n",
    "        decimal *= -1\n",
    "    \n",
    "    return decimal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "filepath = 'Data/taxi_gps_data/data/'\n",
    "\n",
    "# Create list of files\n",
    "files = glob.glob(os.path.join(filepath, '*.csv'))\n",
    "\n",
    "# Initialize dictionary to store all vehicle trips in {vehicle_id: trip_data}\n",
    "all_vehicles = {}\n",
    "\n",
    "# Loop through all files\n",
    "for file in files:\n",
    "    # Take extension out of filename\n",
    "    filename = file.split('.')[0]\n",
    "    # Take filepath out of filename\n",
    "    filename = filename.split('/')[-1]\n",
    "    # Read the trip and clean the data\n",
    "    this_trip = pd.read_csv(file)\n",
    "    this_trip['Time'] = pd.to_datetime(this_trip['Time'])\n",
    "    this_trip['Time_diff'] = this_trip['Time'].diff()\n",
    "    this_trip['Location'] = list(zip(this_trip['Latitude'], this_trip['Longitude']))\n",
    "    this_trip['Distance'] = this_trip.apply(calculate_incremental_distance, df = this_trip, axis=1)\n",
    "    # Save the trip data to a dictionary with the filename as the key \n",
    "    all_vehicles[filename] = this_trip\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New GoMetro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_files(directory):\n",
    "    \"\"\"\n",
    "    Reads in all CSV files in the specified directory and returns a dictionary of Pandas DataFrames.\n",
    "    The DataFrame key is generated from the characters after the second \"-\" in the filename but before \".csv\".\n",
    "    \"\"\"\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    data_frames = {}\n",
    "    for file in csv_files:\n",
    "        print(\"Processing\", file)\n",
    "        # Extract key from filename\n",
    "        key = file.split(\"-\")[2].split(\".csv\")[0].strip()\n",
    "\n",
    "        # Read CSV file into DataFrame\n",
    "        path = os.path.join(directory, file)\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # Check if latitude and longitude columns need to be converted from DMS to decimal\n",
    "        # if ('Latitude' in df.columns) and ('Longitude' in df.columns):\n",
    "        #     lat_col = df['Latitude']\n",
    "        #     lon_col = df['Longitude']\n",
    "        #     if any(isinstance(val, str) for val in lat_col) and any(isinstance(val, str) for val in lon_col):\n",
    "        #         # Convert latitude and longitude values from DMS to decimal\n",
    "        #         df['Latitude'] = df['Latitude'].apply(dms_to_decimal)\n",
    "        #         df['Longitude'] = df['Longitude'].apply(dms_to_decimal)\n",
    "\n",
    "        # Add time-related columns and drop unnecessary columns\n",
    "        df['Time'] = pd.to_datetime(df['Date'] + ' ' + df['Timestamp'])\n",
    "        df['Time_diff'] = df['Time'].diff()\n",
    "        df['Distance_calc'] = df.apply(calculate_incremental_distance, df=df, axis=1)\n",
    "        df.drop(['Date', 'Timestamp'], axis=1, inplace=True)\n",
    "            \n",
    "        # Add to dictionary\n",
    "        data_frames[key] = df\n",
    "        \n",
    "    return data_frames\n",
    "\n",
    "\n",
    "all_vehicles = read_csv_files(\"Data/Output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for vehicle in all_vehicles:\n",
    "    odometer = all_vehicles[vehicle]['Distance'].sum()/1e3\n",
    "    diff = odometer - all_vehicles[vehicle]['Distance_calc'].sum()\n",
    "    print(\"vehicle\", vehicle, \": \", format((diff/odometer) * 100, \".2f\"), \"% difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vehicles['3.6']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substation Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the substation Shapefile data (input from user)\n",
    "substation_location_data = gpd.read_file('Data/mv_station_position/MV_STATION_POSITION.shp')\n",
    "print(substation_location_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substation_location_data.plot(marker = 'x', color = 'black', label = 'Substations')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract trips and breaks\n",
    "breaks_array[i] corresponds to the break between trips_array[i] and trips_array[i + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_breaks_and_trips(gps_data, min_dwell_time, stop_threshold):\n",
    "    ''' \n",
    "    Function to extract the trip and break segments from vehicle GPS data, based on a given minimum dwell time and stop threshold\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # Initialize the trips and breaks lists\n",
    "    trips = []\n",
    "    breaks = []\n",
    "    \n",
    "    # Assume starts trip moving\n",
    "    stopped = False\n",
    "    \n",
    "    # set starting idx of whatever segment we are on (trip or break)\n",
    "    this_segment_start_idx = 0 \n",
    "    this_segment_end_idx = 0\n",
    "    \n",
    "    for row in gps_data.itertuples():\n",
    "        if row.Speed <= stop_threshold: # If the vehicle is stopped\n",
    "            \n",
    "            # if the vehicle WAS previously moving -- capture a trip segment and start a break segment\n",
    "            if not stopped: \n",
    "                # set end index of trip to the previous index\n",
    "                this_segment_end_idx = row.Index - 1 \n",
    "                # capture trip\n",
    "                trips.append(gps_data.loc[this_segment_start_idx:this_segment_end_idx]) \n",
    "                # reset start index of break to the current index\n",
    "                this_segment_start_idx = row.Index \n",
    "            \n",
    "            stopped = True\n",
    "        else:  # If the vehicle is moving\n",
    "            \n",
    "            # if the vehicle WAS stopped -- capture a break segment and start a trip segment if the break was long enough. \n",
    "            if stopped: \n",
    "                # calculate the amount of time the vehicle was stopped\n",
    "                stopped_time = (row.Time - gps_data.iloc[this_segment_start_idx].Time).total_seconds()\n",
    "                \n",
    "                # if break was long enough (convert min_dwell_time from minutes to seconds)\n",
    "                if stopped_time >= min_dwell_time * 60:  \n",
    "                    this_segment_end_idx = row.Index - 1\n",
    "                    breaks.append(gps_data.loc[this_segment_start_idx:this_segment_end_idx])\n",
    "                    gps_data['charging'].loc[this_segment_start_idx:this_segment_end_idx] = 1\n",
    "                    this_segment_start_idx = row.Index\n",
    "                    \n",
    "                else:#  if the break wasn't long enough then continue logging as a trip\n",
    "                    pass \n",
    "                \n",
    "            stopped = False \n",
    "    # if vehicle is still moving at the end and not already captured, capture the final trip\n",
    "    if not stopped:\n",
    "        trips.append(gps_data.loc[this_segment_start_idx:])\n",
    "        \n",
    "                \n",
    "            \n",
    "    return trips, breaks\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_breaks_and_trips_optimized(gps_data, min_dwell_time, stop_threshold):\n",
    "    ''' Function to extract the trip and break segments from vehicle GPS data, based on a given minimum dwell time and stop threshold'''\n",
    "    \n",
    "    # Initialize the trips and breaks lists\n",
    "    trips = []\n",
    "    breaks = []\n",
    "    # Assume starts trip moving\n",
    "    stopped = False\n",
    "    # set starting idx of whatever segment we are on (trip or break)\n",
    "    this_segment_start_idx = 0 \n",
    "    this_segment_end_idx = 0\n",
    "    \n",
    "    # create a list of tuples containing the indices, speed and times for each GPS data point\n",
    "    gps_points = [(i, row.Speed, row.Time) for i, row in enumerate(gps_data.itertuples())]\n",
    "    \n",
    "    # iterate through the gps_points and group them into trips and breaks\n",
    "    for i, speed, time in gps_points:\n",
    "        if speed <= stop_threshold: # If the vehicle is stopped\n",
    "            if not stopped:   # if the vehicle WAS previously moving -- capture a trip segment and start a break segment\n",
    "                # set end index of trip to the previous index\n",
    "                this_segment_end_idx = i - 1 \n",
    "                # capture trip\n",
    "                trips.append(gps_data.loc[this_segment_start_idx:this_segment_end_idx])\n",
    "                # reset start index of break to the current index\n",
    "                this_segment_start_idx = i \n",
    "            stopped = True\n",
    "        else:  # If the vehicle is moving\n",
    "            if stopped: # if the vehicle WAS stopped -- capture a break segment and start a trip segment if the break was long enough. \n",
    "                # calculate the amount of time the vehicle was stopped\n",
    "                stopped_time = (time - gps_data.iloc[this_segment_start_idx].Time).total_seconds()\n",
    "                # if break was long enough (convert min_dwell_time from minutes to seconds)\n",
    "                if stopped_time/60 >= min_dwell_time:  # convert stopped time from seconds to minutes\n",
    "                    this_segment_end_idx = i - 1\n",
    "                    breaks.append(gps_data.loc[this_segment_start_idx:this_segment_end_idx])\n",
    "                    gps_data['charging'].loc[this_segment_start_idx:this_segment_end_idx] = 1\n",
    "                    this_segment_start_idx = i\n",
    "            stopped = False \n",
    "        \n",
    "    # if vehicle is still stopped at the end, capture the final break\n",
    "    if stopped:\n",
    "        breaks.append(gps_data.loc[this_segment_start_idx:])\n",
    "    else:\n",
    "        # capture the final trip\n",
    "        trips.append(gps_data.loc[this_segment_start_idx:])\n",
    "\n",
    "    return trips, breaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_substations_within_buffer(breaks, substation_location_data, buffer):\n",
    "    '''\n",
    "    Function to find substations near a vehicle's break points (to use as candidate charging stations)\n",
    "    Input: Break data, substation location data, buffer distance\n",
    "    Output: Array of substation locations within the buffer distance of the break points\n",
    "    TODO: Integrate into the solution (extra section in case study in the paper?)\n",
    "    ''' \n",
    "    # Find UTM zone based on the average latitude and longitude of the break data\n",
    "    utm_zone = utm.from_latlon(breaks['Latitude'].mean(), breaks['Longitude'].mean())[2]\n",
    "\n",
    "    # Define the projection\n",
    "    project = pyproj.Transformer.from_crs(\"EPSG:4326\", f\"EPSG:326{utm_zone}\")\n",
    "\n",
    "    # Project the points to the UTM zone\n",
    "    projected_points = breaks.geometry.apply(lambda p: transform(project.transform, p))\n",
    "\n",
    "    # Calculate a buffer of 500m around each point in the projected coordinate system\n",
    "    route_buffer = projected_points.buffer(buffer)\n",
    "\n",
    "    # Define the inverse projection to use (from UTM to WGS84)zone\n",
    "    inv_project = pyproj.Transformer.from_crs(f\"EPSG:326{utm_zone}\", \"EPSG:4326\")\n",
    "\n",
    "    # Transform the projected buffer back to EPSG:4326\n",
    "    buffer_latlon = route_buffer.geometry.apply(lambda p: transform(inv_project.transform, p))\n",
    "\n",
    "    # Convert the route buffer to a GeoDataFrame \n",
    "    route_buffer_gdf = gpd.GeoDataFrame(geometry=buffer_latlon)\n",
    "\n",
    "    # Dissolve the route buffer to a single polygon (avoids issues of overlapping polygons which are inevitable with a high frequency GPS dataset)\n",
    "    route_buffer_gdf_dissolved = route_buffer_gdf.dissolve()\n",
    "\n",
    "    # Merge substations within buffer distance of substations\n",
    "    substations_within_buffer = gpd.sjoin(substation_location_data, route_buffer_gdf_dissolved, op='within')\n",
    "    \n",
    "    # Print number of substations within buffer\n",
    "    print(\"There are\", len(substations_within_buffer['REC_ID'].unique()), \"substations within the buffer\")\n",
    "    \n",
    "    # # Plot route, route buffer, and substations within buffer\n",
    "    # route_buffer_gdf.plot(color = 'blue', alpha = 0.1, label = 'Route Buffer')\n",
    "    # break_locations.plot(ax = plt.gca(), color = 'red', markersize = 0.5, marker = 'o', alpha = 0.5, label = 'Vehicle GPS Locations')\n",
    "    # substations_within_buffer.plot(ax = plt.gca(), color = 'black', marker = 'x', markersize = 40, label = 'Substations')\n",
    "    # plt.legend(loc = 'upper right', bbox_to_anchor = (1,1))\n",
    "    # plt.show()\n",
    "    \n",
    "    return substations_within_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve all breaks ### \n",
    "\n",
    "# Define stop threshold (km/h) that the vehicle must be moving slower than to be considered stopped\n",
    "stop_threshold = 1\n",
    "\n",
    "# Define minimum time (minutes) that the vehicle must be moving slower than stop threshold to be considered on a break\n",
    "min_dwell_time = 60\n",
    "\n",
    "# Define average energy consumption (kWh/km) \n",
    "kWh_km = 0.50\n",
    "\n",
    "# Define average charging rating (kW)\n",
    "charge_rate = 22 \n",
    "\n",
    "# Implement the extract trips and extract breaks functions for all vehicles\n",
    "all_trips = {}\n",
    "all_candidate_nodes = {}\n",
    "\n",
    "for vehicle in all_vehicles:\n",
    "    # Make column to identify whether vehicle is charging or not\n",
    "    all_vehicles[vehicle]['charging'] = 0\n",
    "    \n",
    "    print('Extracting trips and breaks from', vehicle)\n",
    "    trips, breaks = extract_breaks_and_trips_optimized(all_vehicles[vehicle], min_dwell_time, stop_threshold)\n",
    "    all_trips[vehicle] = trips\n",
    "    #feasible_substations = find_substations_within_buffer(breaks, substation_location_data, buffer = 500)\n",
    "    all_candidate_nodes[vehicle] = breaks #+ feasible_substations\n",
    "    \n",
    "    # Calculate energy flow in each step based on vehicle status (charging or not)\n",
    "    all_vehicles[vehicle]['energy_consumed'] = np.where(all_vehicles[vehicle]['charging'] == 0, kWh_km * all_vehicles[vehicle]['Distance']/1e3, 0)\n",
    "    all_vehicles[vehicle]['energy_charged'] = np.where(all_vehicles[vehicle]['charging'] == 1, charge_rate * all_vehicles[vehicle]['Time_diff'].dt.total_seconds()/3600, 0)\n",
    "    \n",
    "\n",
    "    \n",
    "    print('Vehicle', vehicle, 'travelled', round(all_vehicles[vehicle]['Distance'].sum()/1e3,2),'km with', \n",
    "              len(trips), 'trips and', len(breaks), 'breaks and consumed',\n",
    "              round(all_vehicles[vehicle]['energy_consumed'].sum(),2) ,'kWh and charged',\n",
    "              round(all_vehicles[vehicle]['energy_charged'].sum(),2), 'kWh \\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_slow_periods(df):\n",
    "    # Initialize an empty list to store the periods of slow speed\n",
    "    slow_periods = []\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    # Loop through the dataframe\n",
    "    for i in range(len(df)):\n",
    "        # If the speed is less than 3 km/h, mark the start of a potential slow period\n",
    "        if df.loc[i, 'Speed'] < 2:\n",
    "            j = i + 1\n",
    "            slow_start = df.loc[i, 'Time']\n",
    "            \n",
    "            # Continue looping until the speed is greater than or equal to 3 km/h\n",
    "            while j < len(df) and df.loc[j, 'Speed'] < 3:\n",
    "                j += 1\n",
    "            \n",
    "            # If the slow period lasted at least 60 minutes, save it to the list of slow periods\n",
    "            if (df.loc[j-1, 'Time'] - slow_start).total_seconds() >= 3600:\n",
    "                if (j-1) not in end_indices:\n",
    "                    slow_periods.append(df.loc[i:j-1])\n",
    "                    start_indices.append(i)\n",
    "                    end_indices.append(j-1)\n",
    "    \n",
    "    # Return a dataframe containing all the slow periods\n",
    "    return pd.concat(slow_periods), start_indices, end_indices\n",
    "all_breaks = {}\n",
    "all_starts = {}\n",
    "all_ends = {}\n",
    "polygons ={}\n",
    "for vehicle in all_vehicles:\n",
    "    all_breaks[vehicle], all_starts[vehicle], all_ends[vehicle] = get_slow_periods(all_vehicles[vehicle])\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output for GridSim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cluster_locations(df):\n",
    "    coords = np.radians(df[['Latitude', 'Longitude']])\n",
    "    scaler = StandardScaler().fit(coords)\n",
    "    coords_scaled = scaler.transform(coords)\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=1).fit(coords_scaled)\n",
    "    df['Cluster'] = dbscan.labels_\n",
    "    \n",
    "    # Plotting \n",
    "    clusters = df.groupby('Cluster')\n",
    "    fig, ax = plt.subplots(figsize=[10, 6])\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'gray', 'brown', 'pink']\n",
    "    for name, group in clusters:\n",
    "        if name != -1:\n",
    "            ax.scatter(group.Longitude, group.Latitude, c=colors[name % len(colors)], label=name, alpha=0.5)\n",
    "    ax.scatter(df[df.Cluster == -1].Longitude, df[df.Cluster == -1].Latitude, c='black', marker='x', label='Outliers', alpha=0.5)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "   # plt.show()\n",
    "    return df\n",
    "dbscan_clusters = {}\n",
    "for vehicle in all_breaks:\n",
    "    cluster_labels = cluster_locations(all_breaks[vehicle])\n",
    "    dbscan_clusters[vehicle] = cluster_labels.groupby('Cluster').mean(['Latitude', 'Longitude'])\n",
    "    \n",
    "# output the cluster center longitude and latitudes to a csv file, using the vehicle ID as name of file\n",
    "for vehicle in dbscan_clusters:\n",
    "    #mkdir 'ForGridSim' if does not exist\n",
    "    if not os.path.exists('ForGridSim/dbscan_cluster_centers'):\n",
    "        os.makedirs('ForGridSim/dbscan_cluster_centers')\n",
    "\n",
    "    dbscan_clusters[vehicle][['Latitude','Longitude']].to_csv('ForGridSim/dbscan_cluster_centers/dbscan_cluster_centers' + vehicle + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Function to calculate the Haversine distance between two lat/lon points in kilometers\n",
    "\n",
    "    R = 6371  # Radius of the earth in km\n",
    "\n",
    "    dLat = math.radians(lat2 - lat1)\n",
    "    dLon = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + \\\n",
    "        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * \\\n",
    "        math.sin(dLon / 2) * math.sin(dLon / 2)\n",
    "\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    distance = R * c  # Distance in km\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_nodes(df, n, min_dist):\n",
    "\n",
    "    # loop through all the candidate node datafrmes in test_break_set, and save the top 5 nodes with most time spent\n",
    "    times = []\n",
    "    for node in df:\n",
    "        times.append(node['Time_diff'].dt.total_seconds().sum())\n",
    "\n",
    "    # find the indeces in the times list of the top 5 nodes with most time spent\n",
    "    sorted_nodes = np.argsort(times)[::-1]#[-30:]\n",
    "            \n",
    "    # filtered_nodes = [test_break_set[sorted_nodes[0]]]\n",
    "    filtered_nodes =[df[sorted_nodes[0]]]\n",
    "    for node in np.take(df, sorted_nodes[1:], axis=0):\n",
    "        too_close = False\n",
    "        for filtered_node in filtered_nodes:\n",
    "            if haversine(node['Latitude'].mean(), node['Longitude'].mean(),\n",
    "                        filtered_node['Latitude'].mean(), filtered_node['Longitude'].mean()) < min_dist:\n",
    "                too_close = True\n",
    "                break\n",
    "        if not too_close:\n",
    "            filtered_nodes.append(node)\n",
    "        if len(filtered_nodes) == n:\n",
    "            break\n",
    "\n",
    "    # get the mean lat and long of the filtered nodes\n",
    "    locations = []\n",
    "    for node in filtered_nodes:\n",
    "        locations.append([node['Latitude'].mean(), node['Longitude'].mean()])\n",
    "\n",
    "    # calculate pairwise distances between all locations\n",
    "    distances = []\n",
    "    for i in range(len(locations)):\n",
    "        row = []\n",
    "        for j in range(len(locations)):\n",
    "            dist = haversine(locations[i][0], locations[i][1], locations[j][0], locations[j][1]) * 1e3 # convert from km to m\n",
    "            row.append(dist)\n",
    "        distances.append(row)\n",
    "    \n",
    "    times = [] \n",
    "    for node in filtered_nodes:\n",
    "        times.append(node['Time_diff'].dt.total_seconds().sum()/60)\n",
    "\n",
    "    return distances, locations, times\n",
    "\n",
    "n = 10\n",
    "buffer = 0.150 # km \n",
    "\n",
    "for vehicle in all_candidate_nodes:\n",
    "    dist, loc, time = get_top_n_nodes(all_candidate_nodes[vehicle], n, buffer)\n",
    "    df =pd.DataFrame(loc, columns = ['Latitude', 'Longitude'])\n",
    "    df['Dwell_time_(mins)'] = time\n",
    "    for i in range(len(dist)):\n",
    "        df['Dist_for_loc_' + str(i) + '_(meters)'] = dist[i]\n",
    "    df.to_csv('ForGridSim/break_period_nodes/' + vehicle + '_nodes.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert break periods into polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_charging_area(gdf, buffer_size):\n",
    "\n",
    "    # Find UTM zone based on the average latitude and longitude of the route\n",
    "    utm_zone = utm.from_latlon(gdf['Latitude'].mean(), gdf['Longitude'].mean())[2]\n",
    "\n",
    "    # Define the projection\n",
    "    project = pyproj.Transformer.from_crs(\"EPSG:4326\", f\"EPSG:326{utm_zone}\")\n",
    "\n",
    "    # Project the points to the UTM zone\n",
    "    projected_points = gdf.geometry.apply(lambda p: transform(project.transform, p))\n",
    "\n",
    "    # Calculate a buffer of size 'buffer_size' (meters) around each point in the projected coordinate system\n",
    "    buffer = projected_points.buffer(buffer_size)\n",
    "\n",
    "    # Define the inverse projection to use (from UTM to WGS84)zone\n",
    "    inv_project = pyproj.Transformer.from_crs(f\"EPSG:326{utm_zone}\", \"EPSG:4326\")\n",
    "\n",
    "    # Transform the projected buffer back to EPSG:4326\n",
    "    buffer_latlon = buffer.geometry.apply(lambda p: transform(inv_project.transform, p))\n",
    "\n",
    "    # Convert the buffer to a GeoDataFrame \n",
    "    buffer_gdf = gpd.GeoDataFrame(geometry=buffer_latlon)\n",
    "    \n",
    "\n",
    "    # Dissolve the route buffer to a single polygon (avoids issues of overlapping polygons which are inevitable with a high frequency GPS dataset)\n",
    "    buffer_gdf_dissolved = buffer_gdf.dissolve()\n",
    "    \n",
    "    # Calculate total dwelling time in this charging area\n",
    "    buffer_gdf_dissolved['dwell_time'] = (gdf['Time_diff'].dt.total_seconds()/60).sum()\n",
    "\n",
    "    return buffer_gdf_dissolved\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GDFs not working so test with points #### \n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "buffer_size = 100\n",
    "charging_areas = {}\n",
    "for vehicle in all_breaks:\n",
    "    this_vehicle_charging_areas = []\n",
    "    for break_period in all_breaks[vehicle]:\n",
    "    \n",
    "        # create Points from lat/lon of break periods\n",
    "        break_period['geometry'] = [Point(xy) for xy in zip(break_period['Longitude'], break_period['Latitude'])]\n",
    "        \n",
    "        \n",
    "        # set the CRS to WGS84 (lat/lon)\n",
    "        break_period = gpd.GeoDataFrame(break_period, geometry = 'geometry', crs = \"EPSG:4326\")\n",
    "\n",
    "        # Get the charging area (overlap of buffered break points) and the dwell time in that area\n",
    "        charging_area = create_charging_area(break_period, buffer_size)\n",
    "\n",
    "        # Add the charging area to the list of charging areas for this vehicle\n",
    "        this_vehicle_charging_areas.append(charging_area)\n",
    "        \n",
    "    # Convert the list of charging areas to a GeoDataFrame    \n",
    "    gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        'geometry': [poly[0].iloc[0].geometry for poly in this_vehicle_charging_areas],\n",
    "        'dwell_time': [poly[1] for poly in this_vehicle_charging_areas]\n",
    "    },\n",
    "    crs=polygons[0][0].crs # assuming all polygons have the same CRS\n",
    "    )\n",
    "    \n",
    "    # Add the charging areas to the dictionary of charging areas indexed by vehicle\n",
    "    charging_areas[vehicle] = gdf\n",
    "    \n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = charging_areas[vehicle]\n",
    "\n",
    "sjoin = gpd.sjoin(gdf, gdf)\n",
    "\n",
    "overlaying_buffers_gdf = sjoin.loc[sjoin.index != sjoin.index_right]\n",
    "overlaying_buffers_gdf#grr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_charging_areas(gdf):\n",
    "    merged = gpd.GeoDataFrame(geometry=[], crs=gdf.crs)\n",
    "    for idx, row in gdf.iterrows():\n",
    "        poly = row['geometry']\n",
    "        dwell_time = row['dwell_time']\n",
    "        \n",
    "        # find all the polygons that intersect with the current polygon\n",
    "        intersects = gdf[gdf.geometry.intersects(poly)]\n",
    "        \n",
    "        # merge the polygons and sum the dwell times\n",
    "        merged_poly = intersects.geometry.unary_union\n",
    "        merged_dwell_time = intersects['dwell_time'].sum()\n",
    "        \n",
    "        # add the merged polygon to the merged dataframe\n",
    "        merged = merged.append({'geometry': merged_poly, 'dwell_time': merged_dwell_time}, ignore_index=True)\n",
    "\n",
    "    # reset the index and convert the 'dwell_time' column to float\n",
    "    merged = merged.reset_index(drop=True)\n",
    "    merged['dwell_time'] = merged['dwell_time'].astype(float)\n",
    "\n",
    "    # only take unique results from the merged dataframe\n",
    "    unique = merged.drop_duplicates(subset=['geometry'])\n",
    "    \n",
    "    return unique\n",
    "\n",
    "collapsed_charging_areas = {}   \n",
    "\n",
    "for vehicle in charging_areas:\n",
    "    collapsed_charging_areas[vehicle] = collapse_charging_areas(charging_areas[vehicle])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vehicle in collapsed_charging_areas:\n",
    "    #sort by dwell time\n",
    "    collapsed_charging_areas[vehicle] = collapsed_charging_areas[vehicle].sort_values(by='dwell_time', ascending=False)\n",
    "    # output to file \n",
    "    if not os.path.exists('ForGridSim/collapsed_polgyons'):\n",
    "        os.makedirs('ForGridSim/collapsed_polgyons')\n",
    "        \n",
    "    # convert centroid to lat/lon\n",
    "    collapsed_charging_areas[vehicle]['location'] = collapsed_charging_areas[vehicle].centroid.apply(lambda p: (p.y, p.x))\n",
    "    \n",
    "    collapsed_charging_areas[vehicle][['location','dwell_time']].to_csv(f'ForGridSim/collapsed_polgyons/{vehicle}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import cascaded_union\n",
    "\n",
    "def merge_polygons(df, geom_col):\n",
    "    # create a new column to store individual polygon IDs\n",
    "    df['poly_id'] = range(len(df))\n",
    "    \n",
    "    # create a list of tuples of each polygon and its ID\n",
    "    polys = [(poly, id) for poly, id in zip(df[geom_col], df['poly_id'])]\n",
    "    \n",
    "    # define an empty list to store intersects groups\n",
    "    intersect_groups = []\n",
    "    \n",
    "    # iterate through each polygon tuple\n",
    "    for i, (poly_1, id_1) in enumerate(polys):\n",
    "        # check intersection against all other polygons after the current one\n",
    "        for j, (poly_2, id_2) in enumerate(polys[i+1:]):\n",
    "            if poly_1.intersects(poly_2):\n",
    "                # add both IDs to the intersection group list\n",
    "                intersect_group = set([id_1, id_2])\n",
    "                \n",
    "                # check if either ID is already in another intersect group\n",
    "                in_group = False\n",
    "                for group in intersect_groups:\n",
    "                    if intersect_group.intersection(group):\n",
    "                        # if so, merge the groups\n",
    "                        group.update(intersect_group)\n",
    "                        intersect_group = group\n",
    "                        in_group = True\n",
    "                \n",
    "                # if not, add this intersect group as a new item\n",
    "                if not in_group:\n",
    "                    intersect_groups.append(intersect_group)\n",
    "    \n",
    "    # iterate through each intersect group and merge their polygons\n",
    "    merged_polys = []\n",
    "    for group in intersect_groups:\n",
    "        group_polys = [polys[id][0] for id in group]\n",
    "        merged_poly = cascaded_union(group_polys)\n",
    "        merged_polys.append(merged_poly)\n",
    "    \n",
    "    # create a final list of merged polygons and individual polygons that were not merged\n",
    "    final_polys = []\n",
    "    for i, (poly, id) in enumerate(polys):\n",
    "        if id not in set.union(*intersect_groups):\n",
    "            final_polys.append(poly)\n",
    "    \n",
    "    # add the merged polygons to the final list\n",
    "    final_polys += merged_polys\n",
    "    \n",
    "    # convert the final list back to a GeoSeries and return it\n",
    "    return gpd.GeoSeries(final_polys)\n",
    "polygons=[]\n",
    "for vehicle in collapsed_charging_areas:\n",
    "    merged = merge_polygons(collapsed_charging_areas[vehicle], 'geometry')\n",
    "    polygons.append(merged)\n",
    "for polygon in polygons:\n",
    "    polygon.plot()\n",
    "# find the centroid of all the polygons and multipolygons in collapsed_charging_areas\n",
    "for vehicle in collapsed_charging_areas:\n",
    "    collapsed_charging_areas[vehicle]['centroid'] = collapsed_charging_areas[vehicle]['geometry'].apply(lambda p: p.centroid)\n",
    "    print(len(collapsed_charging_areas[vehicle]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract top-n break points for each taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dwelling_times = {}\n",
    "\n",
    "for vehicle in all_candidate_nodes:\n",
    "    dwelling_times = []\n",
    "    for break_period in all_candidate_nodes[vehicle]:\n",
    "        dwelling_times.append(break_period['Time_diff'].dt.total_seconds().sum()/60)\n",
    "        \n",
    "    sorted_nodes = np.argsort(dwelling_times)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    all_dwelling_times[vehicle] = dwelling_times\n",
    "    \n",
    "\n",
    "# loop through all dwelling times for each vehicle, and use the index of the top 5 dwelling times to get the top5 candidate noede\n",
    "len(all_dwelling_times[vehicle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe out of locations and time, where locations is a list of lists of lat and long, and time is a list of times\n",
    "df =pd.DataFrame(loc, columns = ['Latitude', 'Longitude'])\n",
    "df['Dwell_time_mins'] = time\n",
    "# add dist matrix to dataframe (5 new columns)\n",
    "for i in range(len(dist)):\n",
    "    df['dist' + str(i)] = dist[i]\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tier 0: Finds the top 5 breakpoints for each taxi and how much time spent at each, regardless of how far apart they are from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_break_set = all_candidate_nodes[vehicle]\n",
    "\n",
    "# loop through all the candidate node datafrmes in test_break_set, and save the top 5 nodes with most time spent\n",
    "times = []\n",
    "for node in test_break_set:\n",
    "    times.append(node['Time_diff'].dt.total_seconds().sum())\n",
    "    if node['Time_diff'].dt.total_seconds().sum() < 3600:\n",
    "        print('too short')\n",
    "\n",
    "# find the indeces in the times list of the top 5 nodes with most time spent\n",
    "top_5 = np.argsort(times)[-5:]\n",
    "\n",
    "# get the top 5 nodes from test_break_set\n",
    "top_5_nodes = [test_break_set[i] for i in top_5]\n",
    "\n",
    "# get the mean lat and long of the top 5 nodes\n",
    "locations = []\n",
    "for node in top_5_nodes:\n",
    "    locations.append([node['Latitude'].mean(), node['Longitude'].mean()])\n",
    "\n",
    "\n",
    "# Calculate pairwise distances between all locations\n",
    "distances = []\n",
    "for i in range(len(locations)):\n",
    "    row = []\n",
    "    for j in range(len(locations)):\n",
    "        dist = haversine(locations[i][0], locations[i][1], locations[j][0], locations[j][1]) * 1e3 # convert from km to m\n",
    "        row.append(dist)\n",
    "    distances.append(row)\n",
    "    \n",
    "# Print the result\n",
    "for row in distances:\n",
    "    print(row)\n",
    "    \n",
    "# Calculate time spent at each location\n",
    "dwell_times = []\n",
    "for node in top_5_nodes:\n",
    "    print(node['Time_diff'].dt.total_seconds().sum()/3600)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tier 1: Find the top 5 break points that are min_dist away from each other, and the time spent at each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist = 0.20 # km\n",
    "\n",
    "test_break_set = all_candidate_nodes[vehicle]\n",
    "\n",
    "# loop through all the candidate node datafrmes in test_break_set, and save the top 5 nodes with most time spent\n",
    "times = []\n",
    "for node in test_break_set:\n",
    "    times.append(node['Time_diff'].dt.total_seconds().sum())\n",
    "\n",
    "# find the indeces in the times list of the top 5 nodes with most time spent\n",
    "sorted_nodes = np.argsort(times)#[-30:]\n",
    "\n",
    "filtered_nodes = [test_break_set[sorted_nodes[0]]]\n",
    "for node in np.take(test_break_set, sorted_nodes[1:], axis=0):\n",
    "    too_close = False\n",
    "    for filtered_node in filtered_nodes:\n",
    "        if haversine(node['Latitude'].mean(), node['Longitude'].mean(),\n",
    "                     filtered_node['Latitude'].mean(), filtered_node['Longitude'].mean()) < min_dist:\n",
    "            too_close = True\n",
    "            break\n",
    "    if not too_close:\n",
    "        filtered_nodes.append(node)\n",
    "    if len(filtered_nodes) == 5:\n",
    "        break\n",
    "\n",
    "# get the mean lat and long of the filtered nodes\n",
    "locations = []\n",
    "for node in filtered_nodes:\n",
    "    locations.append([node['Latitude'].mean(), node['Longitude'].mean()])\n",
    "\n",
    "# calculate pairwise distances between all locations\n",
    "distances = []\n",
    "for i in range(len(locations)):\n",
    "    row = []\n",
    "    for j in range(len(locations)):\n",
    "        dist = haversine(locations[i][0], locations[i][1], locations[j][0], locations[j][1]) * 1e3 # convert from km to m\n",
    "        row.append(dist)\n",
    "    distances.append(row)\n",
    "\n",
    "# print the result\n",
    "for row in distances:\n",
    "    print(row)\n",
    "    \n",
    "for node in filtered_nodes:\n",
    "    print(node['Time_diff'].dt.total_seconds().sum()/3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximum battery capacity (kWh)\n",
    "battery_cap = 70\n",
    "\n",
    "for vehicle in ['T1001', 'T3001']:\n",
    "    print(\"Simulating\", vehicle)\n",
    "    all_vehicles[vehicle]['SOC'] = battery_cap \n",
    "       \n",
    "    for idx, row in all_vehicles[vehicle].iterrows():\n",
    "        if idx == 0: \n",
    "            all_vehicles[vehicle].loc[idx, 'SOC'] = battery_cap # first observation \n",
    "        else:\n",
    "            # State of charge equals minimum of previous state of charge plus energy charged minus energy consumed in this step or battery capacity\n",
    "            all_vehicles[vehicle].loc[idx, 'SOC'] = np.minimum(all_vehicles[vehicle].loc[idx-1, 'SOC'] + row['energy_charged'] - row['energy_consumed'], battery_cap)\n",
    "    if (all_vehicles[vehicle]['SOC'] < 0).any():\n",
    "        print(vehicle, 'ran out of charge!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vehicle in all_vehicles:\n",
    "    plt.plot(all_vehicles[vehicle].SOC)\n",
    "    plt.ylim(0,70)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, asin\n",
    "\n",
    "def find_close_points(df):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    df['lat_rad'] = df['latitude'].apply(radians)\n",
    "    df['lon_rad'] = df['longitude'].apply(radians)\n",
    "\n",
    "    close_points = []\n",
    "    for i, row_i in df.iterrows():\n",
    "        for j, row_j in df.iterrows():\n",
    "            if i >= j:\n",
    "                continue  # skip self-matches and duplicates\n",
    "            lat1, lon1, lat2, lon2 = row_i['lat_rad'], row_i['lon_rad'], \\\n",
    "                                     row_j['lat_rad'], row_j['lon_rad']\n",
    "            # Compute distance between two points using haversine formula\n",
    "            dlon = lon2 - lon1 \n",
    "            dlat = lat2 - lat1 \n",
    "            a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "            c = 2 * asin(sqrt(a)) \n",
    "            r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "            dist = c * r\n",
    "            \n",
    "            # Check if distance is less than 500m (0.5km)\n",
    "            if dist < 0.500:\n",
    "                close_points.append((i,j))\n",
    "    \n",
    "    return close_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the simulation\n",
    "a = datetime.now()\n",
    "Sim = Simulator(df_array_breaks, df_array_trips, 1.0)\n",
    "Sim.run_simulation()\n",
    "b = datetime.now()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle:\n",
    "    \"\"\"_summary_line_\n",
    "    Class to simulate a vehicle with a battery and a route\n",
    "    \"\"\"\n",
    "    # initiate all the variables\n",
    "    def __init__(self, initial_distance, service_time, vehicle_params, params):\n",
    "        self.capacity = vehicle_params['Capacity'] # kWh\n",
    "        self.consumption = vehicle_params['kWh_km']  # kWh/km\n",
    "        self.charge_steps = vehicle_params['charge_steps'] # kWh\n",
    "        self.charge_rate = vehicle_params['charge_rate'] # list of charging rate at each charge step (kWh/min)\n",
    "        self.break_10 = 0.1 * self.capacity\n",
    "        self.break_5 = 0.05 * self.capacity\n",
    "        self.break_70 = 0.7 * self.capacity\n",
    "        self.distance = initial_distance\n",
    "        self.service_time = service_time\n",
    "        self.total_time_trips = 0.\n",
    "        self.km_so_far = 0.\n",
    "        self.time_break = 0.\n",
    "        self.min_so_far = 0.\n",
    "        self.trips = True\n",
    "        self.breaks = False\n",
    "        self.charger = False\n",
    "        self.was_charging = False\n",
    "        self.end_charging = False\n",
    "        self.indec_cs = 0\n",
    "        self.sim_breaks = {\"Duration\": [], \"Longitude\": [], \"Latitude\": [], \"Order\": [], \"Charged\": [], \"Charging Duration\": [],\n",
    "                          \"Initial minute\": [], \"Initial SoC\": []}\n",
    "        self.sim_trips = {\"Distance\": [], \"Order\": []}\n",
    "        self.order = 0\n",
    "        self.charged = 0.\n",
    "        self.duration = 0.\n",
    "        self.in_m = 0.\n",
    "        self.in_soc = 52.\n",
    "        self.wasted_time = 0.\n",
    "        self.travel_time = 0.\n",
    "        self.not_charging = 0.\n",
    "        # stochastic parameters\n",
    "        self.lambda_dist = params[0]\n",
    "        self.mu_speed = params[1]\n",
    "        self.sigma_speed = params[2]\n",
    "        self.lambda_speed = params[3]\n",
    "        self.omega_speed = params[4]\n",
    "        self.mu_breaks = params[5]\n",
    "        self.sigma_breaks = params[6]\n",
    "        \n",
    "    # set a random wasted time when drivers charge\n",
    "    def set_wasted_time(self, mu=2., sigma=0.33):\n",
    "        return np.random.normal(loc=mu, scale=sigma)\n",
    "    \n",
    "    # simulate charging time\n",
    "    def charge(self, duration):\n",
    "        init_cap = float(self.capacity)\n",
    "        for s in range(len(self.charge_steps)):\n",
    "            if self.capacity < self.charge_steps[s] and duration > 0.:\n",
    "                mins = self.decide_duration(duration, self.charge_steps[s] - self.capacity, s)\n",
    "                self.capacity += mins * self.charge_rate[s]\n",
    "                duration -= mins\n",
    "        self.charged += self.capacity - init_cap\n",
    "        return\n",
    "    \n",
    "    # energy consumption per distance\n",
    "    def calculate_energy(self, distance):\n",
    "        return distance * self.consumption\n",
    "    \n",
    "    \n",
    "        # function used to change between trip and break or viceversa. In both cases, all variables need to be reset\n",
    "    def change_state(self, t):\n",
    "        if self.capacity < 0.:\n",
    "            self.capacity = 0.\n",
    "        if self.trips:\n",
    "            self.trips = False\n",
    "            self.sim_trips[\"Distance\"].append(self.km_so_far)\n",
    "            self.sim_trips['Order'].append(self.order)\n",
    "            self.order += 1\n",
    "            self.breaks = True\n",
    "            self.time_break = np.random.lognormal(self.mu_breaks, self.sigma_breaks)\n",
    "            location = np.random.randint(0, df_total_breaks.shape[0])\n",
    "            while df_total_breaks[\"Inside City\"].values[location] == False:\n",
    "                location = np.random.randint(0, df_total_breaks.shape[0])\n",
    "            self.sim_breaks[\"Duration\"].append(self.time_break)\n",
    "            self.sim_breaks[\"Longitude\"].append(df_total_breaks[\"Longitude\"].values[location])\n",
    "            self.sim_breaks['Latitude'].append(df_total_breaks[\"Latitude\"].values[location])\n",
    "            self.sim_breaks['Order'].append(self.order)\n",
    "            self.in_m = float(t / 60.)\n",
    "            self.in_soc = float(self.capacity)\n",
    "            self.charged = 0.\n",
    "            self.duration = 0.\n",
    "            self.order += 1\n",
    "            self.min_so_far = 0.\n",
    "            if (self.time_break >= 30. and self.capacity <= self.break_70) or self.capacity <= self.break_10:\n",
    "                self.charger = True\n",
    "                self.was_charging = True\n",
    "        else:\n",
    "            if self.total_time_trips < t * self.service_time / 100.:\n",
    "                self.trips = True\n",
    "                self.breaks = False\n",
    "                self.sim_breaks['Initial minute'].append(self.in_m)\n",
    "                self.sim_breaks['Initial SoC'].append(self.in_soc)\n",
    "                if self.duration > self.time_break:\n",
    "                    self.duration = self.time_break\n",
    "                if self.charged + self.in_soc > 52.:\n",
    "                    self.charged = 52. - self.in_soc\n",
    "                self.duration -= self.wasted_time\n",
    "                if self.duration < 0.:\n",
    "                    self.duration = 0.\n",
    "                    self.charged = 0.\n",
    "                    self.capacity = float(self.in_soc)\n",
    "                self.sim_breaks['Charged'].append(self.charged)\n",
    "                self.sim_breaks['Charging Duration'].append(self.duration)\n",
    "                self.distance = np.random.exponential(1. / self.lambda_dist)\n",
    "                self.km_so_far = 0.\n",
    "                self.wasted_time = 0.\n",
    "                self.travel_time = 0.\n",
    "                self.not_charging = 0.\n",
    "            else:\n",
    "                tot_time = self.total_time_trips / (self.service_time / 100.)\n",
    "                self.time_break += (tot_time - t) / 60.\n",
    "                \n",
    "                \n",
    "    # at each interval, change capacity based on what driver is doing\n",
    "    def update_state(self, t):\n",
    "        if self.trips:\n",
    "            # based on statistical distributions, set the speed the driver is using in the interval of time \n",
    "            # and reduce capacity accordingly\n",
    "            stops = np.random.uniform(0.0, 1.0, size=6)\n",
    "            l = 6 - len(stops[stops < 0.21752482333083625])\n",
    "            speed = self.omega_speed * np.random.normal(loc=self.mu_speed, scale=self.sigma_speed, size=l) \\\n",
    "                        + (1. - self.omega_speed) * np.random.exponential(1. / self.lambda_speed, size=l)\n",
    "            distance_t = np.sum(speed) / (3.6 * 1000.) * 10.0\n",
    "            self.km_so_far += distance_t\n",
    "            self.capacity -= self.calculate_energy(distance_t)\n",
    "            self.total_time_trips += 60.\n",
    "        if self.breaks:\n",
    "            # if in a break, just wait for next interval of time or increase capacity if driver is charging\n",
    "            if self.travel_time > 0.:\n",
    "                self.travel_time -= 1.\n",
    "            else:\n",
    "                self.min_so_far += 1.\n",
    "                if self.not_charging > 0.:\n",
    "                    self.not_charging -= 1.\n",
    "                else:\n",
    "                    if self.was_charging:\n",
    "                        self.charge(1.)\n",
    "                    if (self.capacity >= 52. or self.min_so_far >= self.time_break) and self.was_charging:\n",
    "                        self.duration = float(self.min_so_far)\n",
    "                        self.was_charging = False\n",
    "                        self.end_charging = True\n",
    "                        if self.capacity > 52.:\n",
    "                            self.capacity = 52.\n",
    "        \n",
    "        # if break/trip has come to an end, change state\n",
    "        if (self.trips and self.km_so_far >= self.distance) or (self.breaks and self.min_so_far >= self.time_break):\n",
    "            self.change_state(t)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple numerical optimisation examples\n",
    "Which breaks to charge at <br>\n",
    "Next step: which _locations_ to charge at <br>\n",
    "Step after that: Redundancy constraint <br>\n",
    "BUT before that... I want to make the sure the energy consumption column makes sense... [not necessary to go super deep on this, because it's not the point of this paper. Can use ev_fleet_sim or whatever to simulate the energy consumption]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of energy consumed along each trip\n",
    "# to do this one, i may have to rework the extract trips and breaks function so that consecutive trips are appended together\n",
    "Ec = []\n",
    "for trip in all_trips[vehicle]:\n",
    "    Ec.append(trip['energy_consumed'].sum())\n",
    "# array of energy recharged at each break\n",
    "Er = []\n",
    "for candidate_node in all_candidate_nodes[vehicle]:\n",
    "    Er.append(candidate_node['energy_charged'].sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting SOC simulation as sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation of vehicle to make sure it is possible\n",
    "# Define maximum battery capacity (kWh)\n",
    "BC = 100\n",
    "\n",
    "for vehicle in ['3.6', '3.7']:\n",
    "    print(\"Simulating\", vehicle)\n",
    "    all_vehicles[vehicle]['SOC'] = BC \n",
    "       \n",
    "    for idx, row in all_vehicles[vehicle].iterrows():\n",
    "        if idx == 0: \n",
    "            all_vehicles[vehicle].loc[idx, 'SOC'] = BC # first observation \n",
    "        else:\n",
    "            # State of charge equals minimum of previous state of charge plus energy charged minus energy consumed in this step or battery capacity\n",
    "            all_vehicles[vehicle].loc[idx, 'SOC'] = np.minimum(all_vehicles[vehicle].loc[idx-1, 'SOC'] + row['energy_charged'] - row['energy_consumed'], BC)\n",
    "    if (all_vehicles[vehicle]['SOC'] < 0).any():\n",
    "        print(vehicle, 'ran out of charge!')\n",
    "        \n",
    "    # plot the results\n",
    "    plt.plot(all_vehicles[vehicle]['SOC'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def identify_charging_opportunities(gps_data, min_dwell_time, stop_threshold):\n",
    "    ''' Function to identify charging opportunities in the gps data'''\n",
    "    \n",
    "    gps_data['charging'] = False\n",
    "    \n",
    "    # Assume starts trip moving\n",
    "    charging = False\n",
    "    # set starting idx of whatever segment we are on (trip or break)\n",
    "    this_segment_start_idx = 0 \n",
    "    this_segment_end_idx = 0\n",
    "    \n",
    "    # create a list of tuples containing the indices, speed and times for each GPS data point\n",
    "    gps_points = [(i, row.Speed, row.Time) for i, row in enumerate(gps_data.itertuples())]\n",
    "    \n",
    "    # iterate through the gps_points and group them into trips and breaks\n",
    "    for i, speed, time in gps_points:\n",
    "        if speed <= stop_threshold: # If the vehicle is stopped\n",
    "            if not stopped:   # if the vehicle WAS previously moving -- capture a trip segment and start a break segment\n",
    "                # set end index of trip to the previous index\n",
    "                this_segment_end_idx = i - 1 \n",
    "                # capture trip\n",
    "                trips.append(gps_data.loc[this_segment_start_idx:this_segment_end_idx])\n",
    "                # reset start index of break to the current index\n",
    "                this_segment_start_idx = i \n",
    "            stopped = True\n",
    "        else:  # If the vehicle is moving\n",
    "            if stopped: # if the vehicle WAS stopped -- capture a break segment and start a trip segment if the break was long enough. \n",
    "                # calculate the amount of time the vehicle was stopped\n",
    "                stopped_time = (time - gps_data.iloc[this_segment_start_idx].Time).total_seconds()\n",
    "                # if break was long enough (convert min_dwell_time from minutes to seconds)\n",
    "                if stopped_time/60 >= min_dwell_time:  # convert stopped time from seconds to minutes\n",
    "                    this_segment_end_idx = i - 1\n",
    "                    breaks.append(gps_data.loc[this_segment_start_idx:this_segment_end_idx])\n",
    "                    gps_data['charging'].loc[this_segment_start_idx:this_segment_end_idx] = 1\n",
    "                    this_segment_start_idx = i\n",
    "            stopped = False \n",
    "        \n",
    "    # if vehicle is still stopped at the end, capture the final break\n",
    "    if stopped:\n",
    "        breaks.append(gps_data.loc[this_segment_start_idx:])\n",
    "    else:\n",
    "        # capture the final trip\n",
    "        trips.append(gps_data.loc[this_segment_start_idx:])\n",
    "\n",
    "    return trips, breaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def find_charging_opportunities(df):\n",
    "    \"\"\"\n",
    "    Iterates through GPS data and creates a new column called 'charging_opportunity',\n",
    "    which = 1 for chunks of consecutive data where the vehicle is at less than 2km/h for\n",
    "    at least 60 minutes, and 0 otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): a DataFrame with datetime and speed columns\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: the original DataFrame with a new column 'charging_opportunity'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a timedelta object for 60 minutes\n",
    "    one_hour = timedelta(minutes=60)\n",
    "    \n",
    "    # Create a new column 'charging_opportunity' and initialize it to 0\n",
    "    df['charging_opportunity'] = 0\n",
    "    \n",
    "    # Loop through the DataFrame and mark chunks of consecutive data where the vehicle\n",
    "    # is at less than 2km/h for at least 60 minutes as charging opportunities\n",
    "    start_time = None\n",
    "    for i, row in df.iterrows():\n",
    "        # If the speed is less than 2km/h and we haven't started a new charging opportunity yet,\n",
    "        # record the start time\n",
    "        if row['Speed'] < 1 and start_time is None:\n",
    "            start_time = row['Time']\n",
    "        # If the Speed is greater than 2km/h or we've reached the end of the DataFrame, \n",
    "        # and we've already recorded a start time, check if the duration is long enough\n",
    "        elif (row['Speed'] >= 1 or i == len(df)-1) and start_time is not None:\n",
    "            duration = row['Time'] - start_time\n",
    "            if duration >= one_hour:\n",
    "                # Mark the charging opportunity as 1 for this chunk of data\n",
    "                df.loc[(df['Time'] >= start_time) & (df['Time'] < row['Time']), 'charging_opportunity'] = 1\n",
    "            # Reset the start time\n",
    "            start_time = None\n",
    "    \n",
    "    return df\n",
    "copy_df = all_vehicles['3.6'].copy()\n",
    "copy_df = find_charging_opportunities(copy_df)\n",
    "\n",
    "(copy_df['charging_opportunity'] - copy_df['charging']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_kWh_km = 0.53 # kWh/km\n",
    "charge_rate = 22 # kW \n",
    "\n",
    "\n",
    "df = all_vehicles['3.6']\n",
    "\n",
    "# create a new column 'group' to identify consecutive sequences of 'charging'\n",
    "df['group'] = (df['charging'] != df['charging'].shift()).cumsum()\n",
    "\n",
    "# group the dataframe by 'group' and apply sum aggregation\n",
    "trip_segments = df.groupby('group').agg({\n",
    "    'charging': 'mean', \n",
    "    'Distance': 'sum', \n",
    "    'Time_diff': 'sum'})\n",
    "trip_segments\n",
    "trip_segments['energy_consumed'] = trip_segments['Distance']/1e3 * avg_kWh_km\n",
    "trip_segments['energy_charged'] = trip_segments['Time_diff'].dt.total_seconds()/3600 * charge_rate\n",
    "# sanity check that the vehicle wouldn't be consuming loads of energy while it's supposed to be charging! \n",
    "# trip_segments['energy_consumed'][trip_segments['charging'] ==1].sum() \n",
    "trip_segments['Time_diff_hrs'] = trip_segments['Time_diff'].dt.total_seconds()/3600\n",
    "trip_segments.groupby('charging').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by 'group' and apply sum aggregation to create trip segments of either charging or discharging energy\n",
    "trip_segments = df.groupby('group').agg({\n",
    "    'charging': 'mean',\n",
    "    'Distance': 'sum',\n",
    "    'Latitude': 'mean',\n",
    "    'Longitude': 'mean',\n",
    "    'Time_diff': 'sum'})\n",
    "trip_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot trip segments latitude and longitude and color the dots by the charging column\n",
    "trip_segments['charging_status'] = np.where(trip_segments['charging'] == 1, 'blue', 'red')\n",
    "plt.scatter(trip_segments['Longitude'], trip_segments['Latitude'], c=trip_segments['charging_status'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# create list of candidate location coordinates\n",
    "CNL = []\n",
    "\n",
    "for break_point in all_candidate_nodes[vehicle]:\n",
    "    CNL.append((break_point['Longitude'].mean(), break_point['Latitude'].mean()))\n",
    "               \n",
    "# Define a threshold distance for group membership\n",
    "threshold = 150  # meters\n",
    "\n",
    "# Compute pairwise distances between all points in CNL\n",
    "distances = cdist(CNL, CNL)\n",
    "\n",
    "# Create an adjacency matrix based on distances below threshold\n",
    "adjacency = distances < threshold\n",
    "\n",
    "# Use depth-first search to find connected components\n",
    "visited = set()\n",
    "CNG = [None] * len(CNL)\n",
    "group_index = 0\n",
    "\n",
    "def dfs(i):\n",
    "    CNG[i] = group_index\n",
    "    visited.add(i)\n",
    "    neighbors = [j for j in range(len(CNL)) if adjacency[i, j] and j not in visited]\n",
    "    for j in neighbors:\n",
    "        dfs(j)\n",
    "\n",
    "for i in range(len(CNL)):\n",
    "    if i not in visited:\n",
    "        dfs(i)\n",
    "        group_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulp import *\n",
    "avg_kWh_km = 0.53 # kWh/km\n",
    "charge_rate = 22 # kW \n",
    "\n",
    "\n",
    "df = all_vehicles['3.6']\n",
    "\n",
    "# create a new column 'group' to identify consecutive sequences of 'charging'\n",
    "df['group'] = (df['charging'] != df['charging'].shift()).cumsum()\n",
    "\n",
    "# group the dataframe by 'group' and apply sum aggregation to create trip segments of either charging or discharging energy\n",
    "trip_segments = df.groupby('group').agg({\n",
    "    'charging': 'mean',\n",
    "    'Distance': 'sum',\n",
    "    'Location': 'first',\n",
    "    'Time_diff': 'sum'})\n",
    "\n",
    "trip_segments['energy_consumed'] = trip_segments['Distance'] / \\\n",
    "    1e3 * avg_kWh_km  # m/1e3 * kWh/km = kWh\n",
    "trip_segments['energy_charged'] = trip_segments['Time_diff'].dt.total_seconds(\n",
    ")/3600 * charge_rate  # hrs * kW = kWh\n",
    "\n",
    "\n",
    "BC = 100  # kWh\n",
    "SOC_max = 1  # %\n",
    "SOC_in = SOC_max\n",
    "SOC_min = 0\n",
    "S_start = 0\n",
    "\n",
    "# amount of energy consumed during this trip segment\n",
    "e_c = trip_segments['energy_consumed'][trip_segments['charging'] == 0].values\n",
    "# amount of energy charged during this trip segment\n",
    "e_r = trip_segments['energy_charged'][trip_segments['charging'] == 1].values\n",
    "if len(e_r) < len(e_c):\n",
    "    # add an element to the end of e_r that takest he battery back up to 100\n",
    "    e_r = np.append(e_r, 100 - e_c[-1])\n",
    "elif len(e_c) < len(e_r):\n",
    "    # add an element to the end of e_c to make them even in length\n",
    "    e_c = np.append(e_c, 0)\n",
    "\n",
    "# amount of energy at each trip segment\n",
    "e = [-e_c[i] + e_r[i] for i in range(len(e_c))]\n",
    "\n",
    "# Sanity check that none of the trip segments are too long\n",
    "for val in e:\n",
    "    if val < (-BC * SOC_max):\n",
    "        raise ValueError(\n",
    "            f\"One of the trip segments requires {val} kWh, which is more than the battery capactiy allows.\")\n",
    "\n",
    "# Define candidate_nodes as a list of integers representing the indices of the stops where charging stations can be built\n",
    "candidate_nodes = range(len(e_r))  # indeces of candidate nodes\n",
    "\n",
    "n = len(e_c)\n",
    "\n",
    "### Define optimization problem\n",
    "model = LpProblem(\"EV charging optimization modell\", LpMinimize)\n",
    "\n",
    "### Define decision variables\n",
    "X = LpVariable.dicts(\"UseLocation\", range(\n",
    "    len(e)), lowBound=0, upBound=1, cat=LpBinary)\n",
    "E = LpVariable.dicts(\"Energy\", range(len(e)), lowBound=0,\n",
    "                     upBound=100, cat=LpContinuous)\n",
    "\n",
    "\n",
    "### Define objective function - minimize number of charging stations\n",
    "model += lpSum(X[i] for i in candidate_nodes)\n",
    "\n",
    "### Constraints\n",
    "\n",
    "# Initial energy level\n",
    "model += E[S_start] == SOC_in * BC\n",
    "\n",
    "\n",
    "for i in range(n-1):\n",
    "    # Energy at next stop (only charge if charging station built there)\n",
    "    model += E[i+1] <= E[i] - e_c[i] + (e_r[i] * X[i])\n",
    "    # Energy does not exceed battery capacity\n",
    "    model += E[i+1] <= BC * SOC_max\n",
    "    # Has enough energy to reach the next stop without going below minimum safe battery level\n",
    "    model += E[i] >= e_c[i] + (SOC_min * BC)\n",
    "\n",
    "\n",
    "# Solve\n",
    "status = model.solve()\n",
    "\n",
    "# print the \"build plan\":\n",
    "build_plan = [i for i in candidate_nodes if X[i].varValue > 0]\n",
    "print('build at nodes: ')\n",
    "print(build_plan)\n",
    "\n",
    "# print the sum of the energy at each node\n",
    "sum1 = sum([E[i].varValue for i in candidate_nodes])\n",
    "\n",
    "plt.plot(candidate_nodes, [\n",
    "         E[i].varValue for i in candidate_nodes], color='r', label='no bonus')\n",
    "plt.scatter(build_plan, [0 for t in build_plan], s=10,\n",
    "            alpha=0.6, color='orange', label='no-bonus charge')\n",
    "\n",
    "# replace the objective function to include a bonus for carrying more energy. This ensures the vehicle charges up as much as possible at each node. The bonus is small enough that it doesn't outweight the cost of building anew station, so we use a weighting factor of 1/(BC * SOC_Max * num_nodes) which would be the bonus for having a full charge  at 100 nodes\n",
    "bonus = BC * SOC_max * len(candidate_nodes)\n",
    "model += lpSum(X[i] for i in candidate_nodes) - 1 / \\\n",
    "    (bonus)*lpSum(E[i] for i in candidate_nodes)\n",
    "status2 = model.solve()\n",
    "\n",
    "# QA the build plan has the same NUMBER of build points\n",
    "build_plan_2 = [i for i in candidate_nodes if X[i].varValue > 0]\n",
    "# assert len(build_plan) == len(build_plan_2)\n",
    "print(len(build_plan), len(build_plan_2))\n",
    "\n",
    "print('build at nodes: ', build_plan_2)\n",
    "plt.plot(candidate_nodes, [\n",
    "         E[i].varValue for i in candidate_nodes], color='b', label='bonus')\n",
    "plt.scatter(build_plan_2, [0 for t in build_plan_2],\n",
    "            s=10, alpha=0.6, color='g', label='charge')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "# print the sum of the energy at each node\n",
    "sum2 = sum([E[i].varValue for i in candidate_nodes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1, sum2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
